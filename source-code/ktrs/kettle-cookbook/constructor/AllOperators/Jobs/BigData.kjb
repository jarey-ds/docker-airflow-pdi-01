<?xml version="1.0" encoding="UTF-8"?>
<job>
  <name>BigData</name>
    <description/>
    <extended_description/>
    <job_version/>
  <directory>&#47;</directory>
  <created_user>-</created_user>
  <created_date>2013&#47;04&#47;10 22:24:27.968</created_date>
  <modified_user>-</modified_user>
  <modified_date>2013&#47;04&#47;10 22:24:27.968</modified_date>
    <parameters>
    </parameters>
    <slaveservers>
    </slaveservers>
<job-log-table><connection/>
<schema/>
<table/>
<size_limit_lines/>
<interval/>
<timeout_days/>
<field><id>ID_JOB</id><enabled>Y</enabled><name>ID_JOB</name></field><field><id>CHANNEL_ID</id><enabled>Y</enabled><name>CHANNEL_ID</name></field><field><id>JOBNAME</id><enabled>Y</enabled><name>JOBNAME</name></field><field><id>STATUS</id><enabled>Y</enabled><name>STATUS</name></field><field><id>LINES_READ</id><enabled>Y</enabled><name>LINES_READ</name></field><field><id>LINES_WRITTEN</id><enabled>Y</enabled><name>LINES_WRITTEN</name></field><field><id>LINES_UPDATED</id><enabled>Y</enabled><name>LINES_UPDATED</name></field><field><id>LINES_INPUT</id><enabled>Y</enabled><name>LINES_INPUT</name></field><field><id>LINES_OUTPUT</id><enabled>Y</enabled><name>LINES_OUTPUT</name></field><field><id>LINES_REJECTED</id><enabled>Y</enabled><name>LINES_REJECTED</name></field><field><id>ERRORS</id><enabled>Y</enabled><name>ERRORS</name></field><field><id>STARTDATE</id><enabled>Y</enabled><name>STARTDATE</name></field><field><id>ENDDATE</id><enabled>Y</enabled><name>ENDDATE</name></field><field><id>LOGDATE</id><enabled>Y</enabled><name>LOGDATE</name></field><field><id>DEPDATE</id><enabled>Y</enabled><name>DEPDATE</name></field><field><id>REPLAYDATE</id><enabled>Y</enabled><name>REPLAYDATE</name></field><field><id>LOG_FIELD</id><enabled>Y</enabled><name>LOG_FIELD</name></field></job-log-table>
<jobentry-log-table><connection/>
<schema/>
<table/>
<timeout_days/>
<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>CHANNEL_ID</id><enabled>Y</enabled><name>CHANNEL_ID</name></field><field><id>LOG_DATE</id><enabled>Y</enabled><name>LOG_DATE</name></field><field><id>JOBNAME</id><enabled>Y</enabled><name>TRANSNAME</name></field><field><id>JOBENTRYNAME</id><enabled>Y</enabled><name>STEPNAME</name></field><field><id>LINES_READ</id><enabled>Y</enabled><name>LINES_READ</name></field><field><id>LINES_WRITTEN</id><enabled>Y</enabled><name>LINES_WRITTEN</name></field><field><id>LINES_UPDATED</id><enabled>Y</enabled><name>LINES_UPDATED</name></field><field><id>LINES_INPUT</id><enabled>Y</enabled><name>LINES_INPUT</name></field><field><id>LINES_OUTPUT</id><enabled>Y</enabled><name>LINES_OUTPUT</name></field><field><id>LINES_REJECTED</id><enabled>Y</enabled><name>LINES_REJECTED</name></field><field><id>ERRORS</id><enabled>Y</enabled><name>ERRORS</name></field><field><id>RESULT</id><enabled>Y</enabled><name>RESULT</name></field><field><id>NR_RESULT_ROWS</id><enabled>Y</enabled><name>NR_RESULT_ROWS</name></field><field><id>NR_RESULT_FILES</id><enabled>Y</enabled><name>NR_RESULT_FILES</name></field><field><id>LOG_FIELD</id><enabled>N</enabled><name>LOG_FIELD</name></field><field><id>COPY_NR</id><enabled>N</enabled><name>COPY_NR</name></field></jobentry-log-table>
<channel-log-table><connection/>
<schema/>
<table/>
<timeout_days/>
<field><id>ID_BATCH</id><enabled>Y</enabled><name>ID_BATCH</name></field><field><id>CHANNEL_ID</id><enabled>Y</enabled><name>CHANNEL_ID</name></field><field><id>LOG_DATE</id><enabled>Y</enabled><name>LOG_DATE</name></field><field><id>LOGGING_OBJECT_TYPE</id><enabled>Y</enabled><name>LOGGING_OBJECT_TYPE</name></field><field><id>OBJECT_NAME</id><enabled>Y</enabled><name>OBJECT_NAME</name></field><field><id>OBJECT_COPY</id><enabled>Y</enabled><name>OBJECT_COPY</name></field><field><id>REPOSITORY_DIRECTORY</id><enabled>Y</enabled><name>REPOSITORY_DIRECTORY</name></field><field><id>FILENAME</id><enabled>Y</enabled><name>FILENAME</name></field><field><id>OBJECT_ID</id><enabled>Y</enabled><name>OBJECT_ID</name></field><field><id>OBJECT_REVISION</id><enabled>Y</enabled><name>OBJECT_REVISION</name></field><field><id>PARENT_CHANNEL_ID</id><enabled>Y</enabled><name>PARENT_CHANNEL_ID</name></field><field><id>ROOT_CHANNEL_ID</id><enabled>Y</enabled><name>ROOT_CHANNEL_ID</name></field></channel-log-table>
   <pass_batchid>N</pass_batchid>
   <shared_objects_file/>
  <entries>
    <entry>
      <name>Amazon EMR Job Executor</name>
      <description/>
      <type>EMRJobExecutorPlugin</type>
      <hadoop_job_name/>
      <hadoop_job_flow_id/>
      <jar_url/>
      <access_key>Encrypted </access_key>
      <secret_key>Encrypted </secret_key>
      <staging_dir/>
      <num_instances>2</num_instances>
      <master_instance_type>Small [m1.small]</master_instance_type>
      <slave_instance_type>Small [m1.small]</slave_instance_type>
      <command_line_args/>
      <blocking>N</blocking>
      <logging_interval>60</logging_interval>
      <hadoop_job_name/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>90</xloc>
      <yloc>30</yloc>
      </entry>
    <entry>
      <name>Amazon Hive Job Executor</name>
      <description/>
      <type>HiveJobExecutorPlugin</type>
      <hadoop_job_name/>
      <hadoop_job_flow_id/>
      <q_url/>
      <access_key>Encrypted </access_key>
      <secret_key>Encrypted </secret_key>
      <bootstrap_actions/>
      <staging_dir/>
      <num_instances>2</num_instances>
      <master_instance_type>Small [m1.small]</master_instance_type>
      <slave_instance_type>Small [m1.small]</slave_instance_type>
      <command_line_args/>
      <alive>N</alive>
      <blocking>N</blocking>
      <logging_interval>60</logging_interval>
      <hadoop_job_name/>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>220</xloc>
      <yloc>30</yloc>
      </entry>
    <entry>
      <name>Hadoop Copy Files</name>
      <description/>
      <type>HadoopCopyFilesPlugin</type>
      <copy_empty_folders>Y</copy_empty_folders>
      <arg_from_previous>N</arg_from_previous>
      <overwrite_files>N</overwrite_files>
      <include_subfolders>N</include_subfolders>
      <remove_source_files>N</remove_source_files>
      <add_result_filesname>N</add_result_filesname>
      <destination_is_a_file>N</destination_is_a_file>
      <create_destination_folder>N</create_destination_folder>
      <fields>
      </fields>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>350</xloc>
      <yloc>30</yloc>
      </entry>
    <entry>
      <name>Hadoop Job Executor</name>
      <description/>
      <type>HadoopJobExecutorPlugin</type>
      <hadoop_job_name/>
      <simple>Y</simple>
      <jar_url/>
      <command_line_args/>
      <simple_blocking>N</simple_blocking>
      <blocking>N</blocking>
      <logging_interval>60</logging_interval>
      <simple_logging_interval>60</simple_logging_interval>
      <hadoop_job_name/>
      <mapper_class/>
      <combiner_class/>
      <reducer_class/>
      <input_path/>
      <input_format_class/>
      <output_path/>
      <output_key_class/>
      <output_value_class/>
      <output_format_class/>
      <hdfs_hostname/>
      <hdfs_port/>
      <job_tracker_hostname/>
      <job_tracker_port/>
      <num_map_tasks>1</num_map_tasks>
      <num_reduce_tasks>1</num_reduce_tasks>
      <user_defined_list>
      </user_defined_list>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>470</xloc>
      <yloc>30</yloc>
      </entry>
    <entry>
      <name>Oozie Job Executor</name>
      <description/>
      <type>OozieJobExecutor</type>
    <jobEntryName>Oozie Job Executor</jobEntryName>
    <blockingPollingInterval>300</blockingPollingInterval>
    <blockingExecution>true</blockingExecution>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>590</xloc>
      <yloc>30</yloc>
      </entry>
    <entry>
      <name>Pentaho MapReduce</name>
      <description/>
      <type>HadoopTransJobExecutorPlugin</type>
      <hadoop_job_name/>
      <map_trans_repo_dir/>
      <map_trans_repo_file/>
      <map_trans_repo_reference/>
      <map_trans/>
      <combiner_trans_repo_dir/>
      <combiner_trans_repo_file/>
      <combiner_trans_repo_reference/>
      <combiner_trans/>
      <combiner_single_threaded>Y</combiner_single_threaded>
      <reduce_trans_repo_dir/>
      <reduce_trans_repo_file/>
      <reduce_trans_repo_reference/>
      <reduce_trans/>
      <reduce_single_threaded>Y</reduce_single_threaded>
      <map_input_step_name/>
      <map_output_step_name/>
      <combiner_input_step_name/>
      <combiner_output_step_name/>
      <reduce_input_step_name/>
      <reduce_output_step_name/>
      <blocking>N</blocking>
      <logging_interval>60</logging_interval>
      <input_path/>
      <input_format_class/>
      <output_path/>
      <clean_output_path>N</clean_output_path>
      <suppress_output_map_key>N</suppress_output_map_key>
      <suppress_output_map_value>N</suppress_output_map_value>
      <suppress_output_key>N</suppress_output_key>
      <suppress_output_value>N</suppress_output_value>
      <output_format_class/>
      <hdfs_hostname/>
      <hdfs_port/>
      <job_tracker_hostname/>
      <job_tracker_port/>
      <num_map_tasks>1</num_map_tasks>
      <num_reduce_tasks>1</num_reduce_tasks>
      <user_defined_list>
      </user_defined_list>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>90</xloc>
      <yloc>110</yloc>
      </entry>
    <entry>
      <name>Pig Script Executor</name>
      <description/>
      <type>HadoopPigScriptExecutorPlugin</type>
    <hdfs_hostname/>
    <hdfs_port/>
    <jobtracker_hostname/>
    <jobtracker_port/>
    <script_file/>
    <enable_blocking>N</enable_blocking>
    <local_execution>N</local_execution>
    <script_parameters>
    </script_parameters>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>220</xloc>
      <yloc>110</yloc>
      </entry>
    <entry>
      <name>Sqoop Export</name>
      <description/>
      <type>SqoopExport</type>
    <jobEntryName>Sqoop Export</jobEntryName>
    <blockingPollingInterval>300</blockingPollingInterval>
    <blockingExecution>true</blockingExecution>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>350</xloc>
      <yloc>110</yloc>
      </entry>
    <entry>
      <name>Sqoop Import</name>
      <description/>
      <type>SqoopImport</type>
    <jobEntryName>Sqoop Import</jobEntryName>
    <blockingPollingInterval>300</blockingPollingInterval>
    <blockingExecution>true</blockingExecution>
      <parallel>N</parallel>
      <draw>Y</draw>
      <nr>0</nr>
      <xloc>470</xloc>
      <yloc>110</yloc>
      </entry>
  </entries>
  <hops>
  </hops>
  <notepads>
  </notepads>
</job>
